import os
import logging
import tempfile
from typing import Tuple

import google.generativeai as genai
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
TEXT_MODEL_NAME = os.getenv("TEXT_MODEL_NAME", "gemini-3.0-pro")
IMAGE_MODEL_NAME = os.getenv("IMAGE_MODEL_NAME", "imagen-3.0-generate-001")

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è Gemini: –ò–ò –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è, –∫–æ–¥ –ª–∏—à—å –ø—Ä–æ–≤–æ–¥–Ω–∏–∫
SYSTEM_INSTRUCTION = (
    "You are an autonomous infographic art director. "
    "Analyse the provided news in Russian or English, decide on the best visual metaphor, "
    "and produce a single, concise English prompt for an elegant, minimalist infographic. "
    "Use only visuals (icons, charts, maps, timelines, silhouettes). Do not put any text into the image. "
    "Return only the final prompt; do not explain the reasoning."
)


def configure_genai() -> None:
    if not GOOGLE_API_KEY:
        raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω GOOGLE_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    genai.configure(api_key=GOOGLE_API_KEY)
    logging.info(
        "GenAI –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å: %s, –º–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: %s",
        TEXT_MODEL_NAME,
        IMAGE_MODEL_NAME,
    )


async def generate_ai_content(user_text: str) -> Tuple[object, str]:
    """–ü–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ–≤–µ—Ä—è–µ–º –≤—ã–±–æ—Ä—É –ò–ò: –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ -> –ø—Ä–æ–º–ø—Ç -> –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."""

    text_model = genai.GenerativeModel(TEXT_MODEL_NAME)

    logging.info("–û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏ –≤ Gemini –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∏")
    prompt_response = text_model.generate_content(
        [
            {"role": "system", "parts": [SYSTEM_INSTRUCTION]},
            {"role": "user", "parts": [f"News text: {user_text}"]},
        ],
        generation_config={"temperature": 0.9, "top_p": 0.95},
    )

    image_prompt = (prompt_response.text or "").strip()
    if not image_prompt:
        raise RuntimeError("Gemini –Ω–µ –≤–µ—Ä–Ω—É–ª –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

    logging.info("–ü—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: %s", image_prompt)

    image_model = genai.ImageGenerationModel(IMAGE_MODEL_NAME)

    logging.info("–ó–∞–ø—Ä–æ—Å Imagen –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∏")
    images = image_model.generate_images(
        prompt=image_prompt,
        number_of_images=1,
        aspect_ratio="3:4",
        safety_filter="block_only_high",
    )

    return images[0], image_prompt


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text

    if not user_text:
        return

    status_message = await update.message.reply_text(
        "üß† –ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç—å –∏ –ø—Ä–∏–¥—É–º—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫—É..."
    )

    try:
        image_result, used_prompt = await generate_ai_content(user_text)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp_file:
            image_path = temp_file.name
            image_result.save(image_path)

        await status_message.edit_text("üé® –†–∏—Å—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")

        with open(image_path, "rb") as photo:
            await update.message.reply_photo(
                photo=photo,
                caption=(
                    "üìä **–ò–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞ –≥–æ—Ç–æ–≤–∞!**\n\n"
                    "_–ò–ò —Ä–µ—à–∏–ª –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ —Ç–∞–∫:_\n"
                    f"{used_prompt}"
                ),
                parse_mode="Markdown",
            )

        await status_message.delete()
    except Exception as e:
        logging.exception("–°–±–æ–π –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∏")
        error_msg = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"
        if "400" in str(e):
            error_msg += (
                "\n\n–í–æ–∑–º–æ–∂–Ω–æ, –≤–∞—à–µ–º—É –∫–ª—é—á—É –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ Imagen 3. "
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–∞—Ä–∏—Ñ –∏–ª–∏ –∑–∞–º–µ–Ω–∏—Ç–µ IMAGE_MODEL_NAME –≤ .env."
            )
        await status_message.edit_text(error_msg)
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω —Å–æ–∑–¥–∞–≤–∞–ª—Å—è
        try:
            if "image_path" in locals() and os.path.exists(image_path):
                os.remove(image_path)
        except OSError:
            logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª %s", image_path)


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∏.\n"
        "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏, –∏ Gemini 3 Pro —Å–∞–º —Ä–µ—à–∏—Ç, –∫–∞–∫ –µ—ë –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å."
    )


def main():
    configure_genai()

    if not TELEGRAM_TOKEN:
        raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω TELEGRAM_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    start_handler = MessageHandler(filters.COMMAND & filters.Regex("^/start$"), start)
    message_handler = MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message)

    application.add_handler(start_handler)
    application.add_handler(message_handler)

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()


if __name__ == "__main__":
    main()
